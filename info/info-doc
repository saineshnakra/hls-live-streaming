## Detailed Documentation: HLS-based Live Streaming Backend
### References:

1. https://blog.logrocket.com/build-video-streaming-server-node/
2. https://github.com/datarhei/restreamer (can use this as a reference)
3. https://www.muvi.com/blogs/video-streaming-server/
4. 
---
### Step-by-Step Guide: Building the Live Streaming Server

This is a detailed explanation of the process to build an HLS-based live streaming server with support for **spatial video** and **adaptive bitrate (ABR)** streaming, using Node.js and FFmpeg. I'll walk you through the steps we took, explaining what each part of the server does, what remains to be done, and how the pieces fit together.

---

### **1. Purpose of the Server**

The goal of this project is to build a **live streaming server** that:
1. **Processes spatial videos** (360° video).
2. **Transcodes video** into multiple bitrates to enable **adaptive bitrate streaming (ABR)**.
3. **Segments the video** into smaller `.ts` chunks using the **HLS (HTTP Live Streaming)** protocol.
4. **Serves** the segmented video and `.m3u8` playlist to clients (e.g., VLC media player, browser with HLS support).
5. Allows the client to switch between different quality streams (240p, 360p, 720p) based on network conditions.

---

### **2. Technologies Used**

1. **Node.js**: JavaScript runtime for building the backend server.
2. **Express.js**: Web framework for routing and API handling.
3. **FFmpeg**: Media processing tool to handle video transcoding, segmenting, and spatial video support.
4. **Fluent-FFmpeg**: A Node.js wrapper around FFmpeg for easier integration with the backend.
5. **Nodemon**: Development tool to automatically restart the server when changes are made.
6. **File System (fs)**: Node.js module for file and directory manipulation.
7. **HLS Protocol**: HTTP-based media streaming protocol for delivering segmented video files (.ts) and playlists (.m3u8) to clients.

---

### **3. Project Structure**

Here's the folder structure for the project:

```
project-root/
│
├── controllers/        # Handles API requests
│   ├── streamController.js
│
├── routes/             # API routes definitions
│   ├── streamRoutes.js
│
├── services/           # Core business logic for video processing
│   ├── streamService.js
│
├── config/             # Configuration files
│   ├── config.js
│
├── public/             # Serves static files (HLS output)
│   └── streams/        # Stores HLS files (e.g., .m3u8 playlists, .ts chunks)
│
├── .env                # Environment variables configuration
├── app.js              # Main entry point of the Node.js app
├── package.json        # Node.js dependencies and metadata
└── README.md           # Project documentation
```

---

### **4. How Each File Works**

#### **4.1 app.js (Main Entry Point)**

- **Purpose**: This file initializes the Express.js app, applies middleware, sets up the routes, and starts the server. It listens for requests and handles them using the routes and controllers defined in the project.

```javascript
require('dotenv').config();
const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const morgan = require('morgan');
const streamRoutes = require('./routes/streamRoutes');

const app = express();

// Middleware setup
app.use(cors());
app.use(helmet());
app.use(morgan('dev'));
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Serve static files (HLS streams)
app.use('/streams', express.static('public/streams'));

// API routes for video streaming
app.use('/api/stream', streamRoutes);

// Error handling middleware
app.use((err, req, res, next) => {
  console.error(err.stack);
  res.status(500).json({ message: 'Something went wrong!' });
});

// Start the server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Server is running on port ${PORT}`);
});
```

#### **4.2 streamRoutes.js (Routing Layer)**

- **Purpose**: This file defines the routes that the server exposes. It maps incoming HTTP requests (like `/start`, `/stop`, `/get`) to the appropriate controller functions.

```javascript
const express = require('express');
const streamController = require('../controllers/streamController');
const router = express.Router();

// Route to start a stream
router.post('/start', streamController.startStream);

// Route to stop a stream
router.post('/stop', streamController.stopStream);

// Route to get the HLS playlist (.m3u8) for a specific stream
router.get('/:streamKey', streamController.getStream);

module.exports = router;
```

#### **4.3 streamController.js (Controller Layer)**

- **Purpose**: The controller handles the API logic. It processes the incoming HTTP requests and calls the appropriate service functions. This layer separates the business logic (services) from the API layer (routes).

```javascript
const streamService = require('../services/streamService');

// Handle request to start the stream
exports.startStream = async (req, res) => {
  const { streamKey, videoUrl } = req.body;

  try {
    await streamService.processStream(streamKey, videoUrl);
    res.json({ message: 'Stream started successfully' });
  } catch (error) {
    console.error("Error starting stream:", error);
    res.status(500).json({ message: 'Error starting stream', error: error.message || error });
  }
};

// Handle request to stop the stream
exports.stopStream = (req, res) => {
  res.json({ message: 'Stream stopped successfully' });
};

// Serve the .m3u8 playlist file
exports.getStream = (req, res) => {
  const streamKey = req.params.streamKey;
  res.sendFile(`/public/streams/${streamKey}/master.m3u8`, { root: '.' });
};
```

#### **4.4 streamService.js (Service Layer)**

- **Purpose**: The core of the video processing logic. This file is responsible for running **FFmpeg** commands to process and segment the video, supporting multiple bitrates for ABR, and handling spatial video formats. It uses **Fluent-FFmpeg** to interface with FFmpeg.

```javascript
const ffmpeg = require('fluent-ffmpeg');
const fs = require('fs');
const config = require('../config/config');

// Function to process video and generate HLS segments
exports.processStream = (streamKey, videoUrl) => {
  return new Promise((resolve, reject) => {
    const streamDir = `${config.streamDir}${streamKey}/`;

    // Ensure the input video file exists
    if (!fs.existsSync(videoUrl)) {
      console.error(`Input video file not found: ${videoUrl}`);
      return reject(new Error(`Input video file not found: ${videoUrl}`));
    }

    // Create output directory if it doesn't exist
    if (!fs.existsSync(streamDir)) {
      console.log(`Creating output directory: ${streamDir}`);
      fs.mkdirSync(streamDir, { recursive: true });
    }

    // FFmpeg command to process spatial videos and create ABR streams
    const ffmpegCommand = ffmpeg(videoUrl)
      .inputOptions([
        '-vf v360=c3x2:equirectangular', // Handle 360° spatial video
      ])
      .output(`${streamDir}output_240p.m3u8`)
      .outputOptions([
        '-vf scale=w=426:h=240',
        '-c:v libx264',
        '-b:v 400k',
        '-hls_time 10',
        '-hls_list_size 0',
        '-hls_segment_filename', `${streamDir}240p_chunk_%03d.ts`,
        '-f hls'
      ])
      .output(`${streamDir}output_360p.m3u8`)
      .outputOptions([
        '-vf scale=w=640:h=360',
        '-c:v libx264',
        '-b:v 800k',
        '-hls_time 10',
        '-hls_list_size 0',
        '-hls_segment_filename', `${streamDir}360p_chunk_%03d.ts`,
        '-f hls'
      ])
      .output(`${streamDir}output_720p.m3u8`)
      .outputOptions([
        '-vf scale=w=1280:h=720',
        '-c:v libx264',
        '-b:v 1500k',
        '-hls_time 10',
        '-hls_list_size 0',
        '-hls_segment_filename', `${streamDir}720p_chunk_%03d.ts`,
        '-f hls'
      ])
      .on('start', (cmdline) => {
        console.log('FFmpeg command:', cmdline);
      })
      .on('error', (err, stdout, stderr) => {
        console.error('FFmpeg error:', err.message);
        console.error('FFmpeg stderr:', stderr);
        reject(new Error(`FFmpeg failed with error: ${err.message}`));
      })
      .on('end', () => {
        console.log('Stream processing completed successfully');
        resolve();
      });

    ffmpegCommand.run();
  });
};
```

---

### **5. Key Functionality of the Server**

1. **Video Processing**:
   - The backend uses **FFmpeg** to process spatial video files (e.g., 360° videos). It transcodes the video into multiple resolutions (240p, 360p, 720p) to support **adaptive bitrate (ABR) streaming**.
  
2. **HLS Segmentation**:
   - The videos are split into

 smaller `.ts` segments (e.g., 10-second chunks) using the HLS protocol. For each resolution, a separate `.m3u8` playlist is created, and a **master playlist** is generated for the player to dynamically select the appropriate stream based on network conditions.

3. **Serving HLS Files**:
   - The server exposes an API to serve the generated `.m3u8` playlist and corresponding `.ts` files. This allows video players to progressively download and play video chunks.

---

### **6. Steps Left to Complete the Project**

#### **6.1 Master Playlist Generation**

The master playlist (`master.m3u8`) must be generated dynamically after the transcoding process. This playlist will allow the client to switch between different bitrates. In `streamService.js`, we already discussed how to implement it.

```javascript
const generateMasterPlaylist = (streamDir) => {
  const masterPlaylist = `
#EXTM3U
#EXT-X-STREAM-INF:BANDWIDTH=400000,RESOLUTION=426x240
output_240p.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=800000,RESOLUTION=640x360
output_360p.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=1500000,RESOLUTION=1280x720
output_720p.m3u8
  `;
  fs.writeFileSync(`${streamDir}master.m3u8`, masterPlaylist);
};
```

#### **6.2 Testing on Multiple Devices**
- **Test on VLC**: Ensure that the stream works on a media player that supports HLS, such as VLC.
- **Browser Testing**: Use a web-based HLS player (like HLS.js) to test the stream in a browser.

#### **6.3 Implement Authentication (Optional)**
You may want to add JWT-based authentication to secure your API endpoints so that only authorized users can start or access streams.

#### **6.4 Performance Optimizations**
- **CDN**: Use a **Content Delivery Network (CDN)** to cache and deliver the HLS files globally for better performance.
- **Error Handling**: Add more robust error handling and logging to catch potential issues with FFmpeg or file I/O.

---

### **7. Testing the Server**

1. **Run the Backend**: Start the server using `nodemon` or `node`.
   ```bash
   npx nodemon app.js
   ```

2. **Send a `POST` Request** to start streaming using **Postman** or **curl**.

3. **Access the Stream**:
   - In **VLC** or any HLS-compatible player, open the master playlist URL:
     ```
     http://localhost:3000/streams/testStream/master.m3u8
     ```

---

### **Conclusion**

By following these steps, we’ve built a powerful live streaming backend that can handle spatial videos, adaptive bitrate streaming (ABR), and HLS segmentation. This allows for a smooth and efficient streaming experience that dynamically adjusts based on the client’s network conditions.
